{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mirakram/Projects/sentiment_analysis/sentiment/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13522 entries, 0 to 13521\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   ID               13522 non-null  object \n",
      " 1   comment_id       13522 non-null  int64  \n",
      " 2   datetime         13522 non-null  object \n",
      " 3   text             13522 non-null  object \n",
      " 4   commenter        13522 non-null  object \n",
      " 5   source           13522 non-null  object \n",
      " 6   Reported by      13520 non-null  object \n",
      " 7   Label            4448 non-null   object \n",
      " 8   Sentment         7695 non-null   object \n",
      " 9   Label for Jafar  0 non-null      float64\n",
      " 10  Comment          107 non-null    object \n",
      "dtypes: float64(1), int64(1), object(9)\n",
      "memory usage: 1.1+ MB\n",
      "None\n",
      "1331 91 0\n",
      "7 57\n"
     ]
    }
   ],
   "source": [
    "from dataset.read_csv import review_data, kapital_val\n",
    "from transformers import BertForSequenceClassification, logging\n",
    "from models.sentiment_classifier import SentimentClassifier\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import  test_data_tokenizer, label_interpreter\n",
    "\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "logging.set_verbosity_warning()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1> Load the model </h1>\n",
    "\n",
    "3 models are available for testing.\n",
    "\n",
    "\"Full Azerbaijani\" has been trained on nearly 48k data. (remaining 2k data has been lost due unstable internet connection during translation using google translate API)\n",
    "\n",
    "Other models are trained on 21k data to get the results faster\n",
    "\n",
    "\n",
    "Time spent for translation algorithm: 24 hours\n",
    "\n",
    "21k dataset training: 38 mins/epoch\n",
    "\n",
    "\n",
    "48k dataset training: 1h 18 mins / epoch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model from models/latest_model.pth ...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "available_models = {\"Azerbaijani\":\"models/latest_model_aze.pth\",\n",
    "                    \"English\": \"models/latest_model.pth\",\n",
    "                    \"Full Azerbaijani\": \"models/latest_model_aze_full.pth\",\n",
    "                    \"kapital original\": \"models/kapital_data.pth\",\n",
    "                    \"kapital mixed\": \"models/kapital_data_3_class.pth\"}\n",
    "\n",
    "\n",
    "test_data = review_data(\"test\")\n",
    "model = SentimentClassifier(2)\n",
    "\n",
    "\n",
    "print('load model from %s ...' % available_models[\"English\"])\n",
    "model.load_state_dict(torch.load(available_models[\"English\"])['state_dict'])\n",
    "print('Done!')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Test single sentence </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kapital bank does not work properly, i tried to increase my balance, it did not upload. I need to choose another bank. Refuse. this is 3rd time, i experience it\n",
      "tensor([0])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from googletrans import Translator\n",
    "review = \"Duzgun istəmir kapital bank az öncə million vasitəsilə balans atkimi etdim, hesaba yuk etməyib digər bankları seçmək lazim İMTİNA. Bu mənim başıma 3-cu dəfədir gəlir bezdirmək\"\n",
    "\n",
    "\n",
    "translator = Translator()\n",
    "review = translator.translate(review, dest='en', src='az').text\n",
    "review = \"kapital bank does not work properly, i tried to increase my balance, it did not upload. I need to choose another bank. Refuse. this is 3rd time, i experience it\"\n",
    "print(review)\n",
    "            \n",
    "model.eval().cpu()\n",
    "\n",
    "input_ids, attention_masks = test_data_tokenizer(review)\n",
    "outputs = model(input_ids= input_ids.unsqueeze(dim= 0),\n",
    "                            attention_mask = attention_masks.unsqueeze(dim = 0))\n",
    "\n",
    "_, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "print(preds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Batch Testing with test data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13522 entries, 0 to 13521\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   ID               13522 non-null  object \n",
      " 1   comment_id       13522 non-null  int64  \n",
      " 2   datetime         13522 non-null  object \n",
      " 3   text             13522 non-null  object \n",
      " 4   commenter        13522 non-null  object \n",
      " 5   source           13522 non-null  object \n",
      " 6   Reported by      13520 non-null  object \n",
      " 7   Label            4448 non-null   object \n",
      " 8   Sentment         7695 non-null   object \n",
      " 9   Label for Jafar  0 non-null      float64\n",
      " 10  Comment          107 non-null    object \n",
      "dtypes: float64(1), int64(1), object(9)\n",
      "memory usage: 1.1+ MB\n",
      "None\n",
      "1331 91 0\n",
      "79 1323\n",
      "if cuda is working 1 min. if not around 10 mins)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 1323/1323 [00:34<00:00, 38.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  tensor(0.0907, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_data = kapital_val(\"train\")\n",
    "\n",
    "dataloader_test = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=1\n",
    ")\n",
    "\n",
    "print(\"if cuda is working 1 min. if not around 10 mins)\")\n",
    "tq = tqdm.tqdm(total = len(dataloader_test))\n",
    "tq.set_description('Test')\n",
    "\n",
    "test_iterator = enumerate(dataloader_test)\n",
    "correct_predictions=0\n",
    "model.eval().cuda()\n",
    "\n",
    "for _, batch in test_iterator:\n",
    "    with torch.no_grad():\n",
    "        input_ids, attention_masks, label = batch\n",
    "\n",
    "        outputs = model(input_ids= input_ids.cuda(),\n",
    "                                attention_mask = attention_masks.cuda())\n",
    "                \n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        correct_predictions += torch.sum(preds == label.cuda())\n",
    "                \n",
    "        tq.update()\n",
    "\n",
    "tq.close()\n",
    "\n",
    "print(\"Accuracy: \", correct_predictions/len(dataloader_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f74f65bb7eaf8fab73e4385f5767264cc423549775116fc297cd951f38e125f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
